# -*- coding: utf-8 -*-
"""m.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/123dMS65Ir7-5vjCsPF5uFuZYHlQVtjtp
"""

import pandas as pd
import numpy as np


df = pd.read_excel('reviews_converted.xlsx')

"""1. How many unique papers are in the dataset?"""

df['Paper_ID'].nunique()

"""2. How many reviews were written in each language?"""

df['Language'].value_counts()

"""3. What is the average confidence score per language?"""

df.groupby('Language')['Confidence'].mean()

"""4. Find the paper with the highest average evaluation score."""

df.groupby('Paper_ID')['Evaluation'].mean().idxmax()

"""5. What percentage of papers were preliminarily accepted vs. rejected?"""

df['Preliminary_Decision'].value_counts(normalize=True) * 100

"""6. How many reviews have missing remarks?"""

df['Remarks'].isna().sum()

"""7. Calculate the mean and standard deviation of confidence scores."""

df['Confidence'].agg(['mean', 'std'])

"""8. How many reviews were submitted on each date?"""

df['Timespan'] = pd.to_datetime(df['Timespan'])
df['Timespan'].value_counts().sort_index()

"""9. Identify the most common evaluation score."""

df['Evaluation'].mode()[0]

"""10.Find papers with at least one review where confidence is 5."""

df[df['Confidence'] == 5]['Paper_ID'].unique()

"""11. Get average orientation per decision type."""

df.groupby('Preliminary_Decision')['Orientation'].mean()

"""12. Find the paper with the most reviews."""

df['Paper_ID'].value_counts().idxmax()

"""13. Determine if there is any correlation between confidence and evaluation."""

df[['Confidence', 'Evaluation']].corr()

"""14. List papers that have conflicting preliminary decisions (if any). (Only possible if decisions differ per review â€” may not apply here if uniform per paper.)"""

df.groupby('Paper_ID')['Preliminary_Decision'].nunique().gt(1).sum()

"""15. How many reviews contain non-null review text?"""

df['Text'].notna().sum()

"""16. Find the average number of words per review."""

df['Text'].dropna().apply(lambda x: len(x.split())).mean()

"""17. Which paper has the longest average review text (by word count)?

"""

df['word_count'] = df['Text'].dropna().apply(lambda x: len(x.split()))
df.groupby('Paper_ID')['word_count'].mean().idxmax()

"""18. What is the distribution of orientation values?"""

df['Orientation'].value_counts()

"""19. Identify the top 5 most frequent words across all reviews (after lowercasing)."""

from collections import Counter
words = ' '.join(df['Text'].dropna().str.lower()).split()
Counter(words).most_common(5)

"""20. What proportion of reviews gave the highest evaluation score?"""

max_eval = df['Evaluation'].max()
(df['Evaluation'] == max_eval).mean() * 100